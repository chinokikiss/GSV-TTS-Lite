<div align="center">
  <a href="é¡¹ç›®ä¸»é¡µé“¾æ¥">
    <img src="awa.gif" alt="Logo" width="320" height="480">
  </a>

  <h1>GPT-SoVITS-RT</h1>

  <p>
    ğŸš€ <b>GPT-SoVITS-RealTime</b> 
    <br>
    A high-performance inference engine specifically designed for the GPT-SoVITS text-to-speech model
  </p>

  <p align="center">
      <a href="LICENSE">
        <img src="https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge" alt="License">
      </a>
      <a href="https://www.python.org/">
        <img src="https://img.shields.io/badge/Python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white" alt="Python Version">
      </a>
      <a href="https://github.com/chinokikiss/GPT-SoVITS-RT/stargazers">
        <img src="https://img.shields.io/github/stars/chinokikiss/GPT-SoVITS-RT?style=for-the-badge&color=yellow&logo=github" alt="GitHub stars">
      </a>
  </p>

  <p>
    <a href="README.md">
      <img src="https://img.shields.io/badge/English-66ccff?style=flat-square&logo=github&logoColor=white" alt="English">
    </a>
    &nbsp;
    <a href="README_ZH.md">
      <img src="https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-ff99cc?style=flat-square&logo=github&logoColor=white" alt="Chinese">
    </a>
  </p>
</div>

<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">
</div>

## å…³äºé¡¹ç›® (About)

æœ¬é¡¹ç›®è¯ç”Ÿçš„åˆè¡·æºäºå¯¹æè‡´æ€§èƒ½çš„è¿½æ±‚ã€‚æˆ‘åœ¨åŸç‰ˆ GPT-SoVITS çš„ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œå—é™äº RTX 3050 (Laptop) çš„ç®—åŠ›ç“¶é¢ˆï¼Œæ¨ç†å»¶è¿Ÿå¾€å¾€éš¾ä»¥æ»¡è¶³å®æ—¶äº¤äº’çš„éœ€æ±‚ã€‚

ä¸ºäº†æ‰“ç ´è¿™ä¸€é™åˆ¶ï¼Œ**GPT-SoVITS-RT** åº”è¿è€Œç”Ÿï¼Œå®ƒæ˜¯åŸºäº **V2Pro** æ¨¡å‹å¼€å‘çš„æ¨ç†åç«¯ã€‚é€šè¿‡ä¸€äº›æ·±åº¦ä¼˜åŒ–æŠ€æœ¯ï¼Œæœ¬é¡¹ç›®æˆåŠŸåœ¨ä½æ˜¾å­˜ç¯å¢ƒä¸‹å®ç°äº†æ¯«ç§’çº§çš„å®æ—¶å“åº”ã€‚

é™¤äº†æ€§èƒ½ä¸Šçš„é£è·ƒï¼Œ**GPT-SoVITS-RT** è¿˜å®ç°äº†**éŸ³è‰²ä¸é£æ ¼çš„è§£è€¦**ï¼Œæ”¯æŒç‹¬ç«‹æ§åˆ¶è¯´è¯äººçš„å£°çº¿ä¸æƒ…æ„Ÿï¼Œå¹¶åŠ å…¥äº†**éŸ³å­—å¯¹é½**ä¸**éŸ³è‰²è¿ç§»**ç­‰ç‰¹è‰²åŠŸèƒ½ã€‚

ä¸ºäº†ä¾¿äºå¼€å‘è€…é›†æˆï¼Œ**GPT-SoVITS-RT** å¤§å¹…ç²¾ç®€äº†ä»£ç æ¶æ„ï¼Œä¸”ä½“ç§¯è¢«å‹ç¼©è‡³ **800MB**ã€‚

## æ€§èƒ½å¯¹æ¯” (Performance)

> [!NOTE]
> **æµ‹è¯•ç¯å¢ƒ**ï¼šå•å¡ NVIDIA GeForce RTX 3050 (Laptop)

| æ¨ç†åç«¯ (Backend)| è®¾ç½® (Settings) | é¦–åŒ…å»¶è¿Ÿ (TTFT) | å®æ—¶ç‡ (RTF) | æ˜¾å­˜ (VRAM) | æå‡å¹…åº¦ |
| :--- | :--- | :---: | :---: | :---: | :--- |
| **Original** | `streaming_mode=3` | 436 ms | 0.381 | 1.6 GB | - |
| **RT Version** | `Flash_Attn=Off` | 150 ms | 0.125 | **0.8 GB** | âš¡ **2.9x** Speed |
| **RT Version** | `Flash_Attn=On` | **133 ms** | **0.108** | **0.8 GB** | ğŸ”¥ **3.3x** Speed |

å¯ä»¥çœ‹åˆ°ï¼Œ**GPT-SoVITS-RT** å®ç°äº† **3x ~ 4x** é€Ÿåº¦æå‡ï¼Œä¸”æ˜¾å­˜å ç”¨ **å‡åŠ**ï¼ğŸš€
<br>

## ç¯å¢ƒå‡†å¤‡ (Prerequisites)

- **Anaconda**
- **CUDA Toolkit**
- **Microsoft Visual C++**

## å¿«é€Ÿå¼€å§‹ (Quick Start)

### å®‰è£…æ­¥éª¤

> [!IMPORTANT]
> ç¡®ä¿é¡¹ç›®æ‰€åœ¨çš„è·¯å¾„æ˜¯çº¯è‹±æ–‡çš„ã€‚

```bash
git clone https://github.com/chinokikiss/GPT-SoVITS-RT
cd GPT-SoVITS-RT

conda create -n gsv-rt python=3.11
conda activate gsv-rt
conda install "ffmpeg"

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip install -r requirements.txt
```

### å¿«é€Ÿä½¿ç”¨

åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª Python è„šæœ¬ï¼Œå³å¯å¼€å§‹ä½“éªŒã€‚

> [!TIP]
> é¦–æ¬¡è¿è¡Œæ—¶ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

#### 1. åŸºç¡€è¯­éŸ³åˆæˆ
```python
import sounddevice as sd
from GPT_SoVITS_RT.TTS import TTS

tts = TTS()

res = tts.infer(
    spk_audio_path="æ‹‰è²\æ—¥é….mp3",
    prompt_audio_path="anan\0102Adv17_AnAn001.ogg",
    prompt_audio_text="ãƒŸãƒªã‚¢ã¯â€¦â€¦æœ¬å½“ã«åˆºã•ã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿ",
    prompt_audio_language="ja",
    text="ã¸ã‡ãƒ¼ã€ã“ã“ã¾ã§ã—ã¦ãã‚Œã‚‹ã‚“ã§ã™ã­",
    text_language="auto",
)

print(res)
sd.play(res["audio_data"], res["samplerate"], blocking=True)
```

#### 2. éŸ³è‰²è¿ç§»
```python
import sounddevice as sd
from GPT_SoVITS_RT.TTS import TTS

tts = TTS()

res = tts.infer_vc(
    spk_audio_path="æ‹‰è²\æ—¥é….mp3",
    prompt_audio_path="anan\0102Adv17_AnAn001.ogg",
    prompt_audio_text="ãƒŸãƒªã‚¢ã¯â€¦â€¦æœ¬å½“ã«åˆºã•ã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿ",
    prompt_audio_language="ja",
)

print(res)
sd.play(res["audio_data"], res["samplerate"], blocking=True)
```

#### 3. æµå¼æ¨ç†
è¿™æ˜¯ GPT-SoVITS-RT çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œèƒ½å¤Ÿå®ç°æä½å»¶è¿Ÿçš„å®æ—¶å¯¹è¯ä½“éªŒã€‚
```python
import queue
import numpy as np
import sounddevice as sd
from GPT_SoVITS_RT.TTS import TTS

tts = TTS()

class AudioStreamer:
    def __init__(self):
        self.q = queue.Queue()
        self.buffer = np.zeros((0, 1), dtype='float32')

    def put(self, data):
        if data.ndim == 1:
            data = data.reshape(-1, 1)
        self.q.put(data)

    def callback(self, outdata, frames, time, status):
        while len(self.buffer) < frames:
            try:
                self.buffer = np.concatenate((self.buffer, self.q.get_nowait()))
            except queue.Empty:
                break
        n = min(len(self.buffer), frames)
        outdata[:n] = self.buffer[:n]
        outdata[n:] = 0
        self.buffer = self.buffer[n:]

streamer = AudioStreamer()

stream = sd.OutputStream(
    samplerate=32000, 
    channels=1, 
    callback=streamer.callback,
    dtype='float32'
)
stream.start()

while True:
    text = input("infer text: ")

    generator = tts.infer_stream(
        spk_audio_path="æ‹‰è²\æ—¥é….mp3",
        prompt_audio_path="anan\0102Adv17_AnAn001.ogg",
        prompt_audio_text="ãƒŸãƒªã‚¢ã¯â€¦â€¦æœ¬å½“ã«åˆºã•ã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿ",
        prompt_audio_language="ja",
        text=text,
        text_language="auto",
        boost_first_chunk=True, # å¦‚æœè®¾ç½®ä¸ºâ€œTrueâ€ï¼Œå¯ä»¥å‡å°‘é¦–åŒ…å»¶è¿Ÿï¼Œä½†å¯èƒ½ä¼šåœ¨çŸ­éŸ³æ®µä¸­äº§ç”Ÿå™ªéŸ³ï¼›è‹¥å¸Œæœ›åˆæˆæ›´ç¨³å®šï¼Œåˆ™åº”å°†å…¶è®¾ç½®ä¸ºâ€œFalseâ€ã€‚
    )

    for audio_data in generator:
        print(audio_data)
        streamer.put(audio_data["audio_data"])

    while not streamer.q.empty() or len(streamer.buffer) > 0:
        sd.sleep(100)
```

<details>
<summary><strong>4. å…¶ä»–æ¥å£</strong></summary>

### 1. æ¨¡å‹åˆå§‹åŒ–ä¸åŠ è½½

#### `init_language_module(languages)`
é¢„åŠ è½½å¿…è¦çš„è¯­è¨€å¤„ç†æ¨¡å—ã€‚

#### `load_gpt_model(model_paths="pretrained_models/s1v3.ckpt")`
å°† GPT æ¨¡å‹æƒé‡ä»æŒ‡å®šè·¯å¾„åŠ è½½åˆ°å†…å­˜ä¸­ã€‚

#### `load_sovits_model(model_paths="pretrained_models/v2Pro/s2Gv2ProPlus.pth")`
å°† SoVITS æ¨¡å‹æƒé‡ä»æŒ‡å®šè·¯å¾„åŠ è½½åˆ°å†…å­˜ä¸­ã€‚

### 2. æ¨¡å‹å¸è½½ä¸åˆ—è¡¨è·å–

#### `unload_gpt_model(model_paths)` / `unload_sovits_model(model_paths)`
ä»å†…å­˜ä¸­å¸è½½æ¨¡å‹ä»¥é‡Šæ”¾èµ„æºã€‚

#### `get_gpt_list()` / `get_sovits_list()`
è·å–å½“å‰å·²åŠ è½½æ¨¡å‹çš„åˆ—è¡¨ã€‚

### 3. éŸ³é¢‘ç¼“å­˜ç®¡ç†

#### `cache_spk_audio(spk_audio_paths)`
é¢„å¤„ç†å¹¶ç¼“å­˜è¯´è¯äººéŸ³é¢‘æ•°æ®ã€‚

#### `cache_prompt_audio(prompt_audio_list)`
é¢„å¤„ç†å¹¶ç¼“å­˜æç¤ºéŸ³é¢‘æ•°æ®ã€‚

#### `del_spk_audio(spk_audio_list)` / `del_prompt_audio(prompt_audio_list)`
ä»ç¼“å­˜ä¸­ç§»é™¤éŸ³é¢‘æ•°æ®ã€‚

#### `get_spk_audio_list()` / `get_prompt_audio_list()`
è·å–ç¼“å­˜ä¸­çš„éŸ³é¢‘æ•°æ®åˆ—è¡¨ã€‚

</details>

## Flash Attn
å¦‚æœä½ è¿½æ±‚**æ›´ä½çš„å»¶è¿Ÿ**å’Œ**æ›´é«˜çš„ååé‡**ï¼Œå¼ºçƒˆå»ºè®®å¼€å¯ `Flash Attention` æ”¯æŒã€‚
ç”±äºè¯¥åº“å¯¹ç¼–è¯‘ç¯å¢ƒæœ‰ç‰¹å®šè¦æ±‚ï¼Œè¯·æ ¹æ®ä½ çš„ç³»ç»Ÿæ‰‹åŠ¨å®‰è£…ï¼š

*   **ğŸ§ Linux / æºç æ„å»º**
    *   å®˜æ–¹ä»“åº“ï¼š[Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)

*   **ğŸªŸ Windows ç”¨æˆ·**
    *   é¢„ç¼–è¯‘ Wheel åŒ…ï¼š[lldacing/flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel/tree/main)

> [!TIP]
> å®‰è£…å®Œæˆåï¼Œåœ¨TTSé…ç½®ä¸­è®¾ç½® `use_flash_attn=True` å³å¯äº«å—åŠ é€Ÿæ•ˆæœï¼ğŸš€

## æœªæ¥è®¡åˆ’ (Future Roadmap)
* [ ] **API & WebUI & æ•´åˆåŒ…**
* [ ] **æ‰¹é‡æ¨ç†**
* [ ] **æ–°æ¶æ„ GPT æ¨¡å‹**

## è‡´è°¢ (Credits)
ç‰¹åˆ«æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®ï¼š
- [RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
- [High-Logic/Genie-TTS](https://github.com/High-Logic/Genie-TTS)

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=chinokikiss/GPT-SoVITS-RT&type=Date)](https://star-history.com/#chinokikiss/GPT-SoVITS-RT&Date)
